{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Allow GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "# Initialize GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the test set for landmarks and for masks.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Rutas a las carpetas de entrenamiento, prueba y validación para imágenes y máscaras\n",
    "test_frames_dir = \"./Frames/TEST\"\n",
    "test_Landmarks_dir = \"./Landmarks/Landmarks/TEST\"\n",
    "test_masks_dir = \"./Mascaras/Mask/TEST\"\n",
    "\n",
    "# Funciones para cargar y preprocesar imagen y máscara y convertirlo a solo un canal\n",
    "def load_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def load_landmarks(file_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(file_path):\n",
    "        image=cv2.imread(os.path.join(file_path, filename))\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images.append(grayscale_image)\n",
    "\n",
    "    stacked_image = np.stack(images, axis=-1)  # axis=-1 indica la dimensión de los canales\n",
    "    stacked_image = stacked_image / 255.0\n",
    "    return stacked_image\n",
    "\n",
    "test_image_files = [os.path.join(test_frames_dir, filename) for filename in os.listdir(test_frames_dir)]\n",
    "test_Landmarks_files = [os.path.join(test_Landmarks_dir, filename) for filename in os.listdir(test_Landmarks_dir)]\n",
    "test_mask_files = [os.path.join(test_masks_dir, filename) for filename in os.listdir(test_masks_dir)]\n",
    "\n",
    "test_images = [load_image(file) for file in test_image_files]\n",
    "test_Landmarks = [load_landmarks(file) for file in test_Landmarks_files]\n",
    "test_masks = [load_image(file) for file in test_mask_files]\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_Landmarks = np.array(test_Landmarks)\n",
    "test_masks = np.array(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "with tf.device('CPU'):\n",
    "    test_dataset_masks = tf.data.Dataset.from_tensor_slices((test_images, test_masks))\n",
    "    test_dataset_masks = test_dataset_masks.batch(BATCH_SIZE)\n",
    "\n",
    "    test_dataset_Landmarks = tf.data.Dataset.from_tensor_slices((test_images, test_Landmarks))\n",
    "    test_dataset_Landmarks = test_dataset_Landmarks.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_landmarks(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy metric for 7 landmarks.\n",
    "    Assumes y_true and y_pred are of shape (batch_size, 112, 112, 7).\n",
    "    \"\"\"\n",
    "    # Extract the landmark values from y_true and y_pred\n",
    "    y_true_landmarks = y_true[..., :7]\n",
    "    y_pred_landmarks = y_pred[..., :7]\n",
    "\n",
    "    # Calculate the element-wise absolute difference\n",
    "    abs_diff = K.abs(y_true_landmarks - y_pred_landmarks)\n",
    "\n",
    "    # Create a mask where each element is 1 if the absolute difference is less than a threshold, otherwise 0\n",
    "    mask = K.cast(K.less(abs_diff, 0.5), dtype=tf.float32)\n",
    "\n",
    "    # Calculate the accuracy for each landmark\n",
    "    landmark_accuracy = K.mean(mask, axis=-1)\n",
    "\n",
    "    # Overall accuracy is the mean accuracy across all landmarks\n",
    "    overall_accuracy = K.mean(landmark_accuracy)\n",
    "\n",
    "    return overall_accuracy\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_flat = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_flat = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_flat * y_pred_flat)\n",
    "    return (2.0 * intersection + smooth) / (tf.keras.backend.sum(y_true_flat) + tf.keras.backend.sum(y_pred_flat) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the model for the masks and the model for the landmarks.\n",
    "\n",
    "landmarks_model_name = \"landmark_20231124-180554\"\n",
    "masks_model_name = \"mascara_20231122-180148\"\n",
    "\n",
    "path_landmarks = \"./Pruebas/{}/model.h5\".format(landmarks_model_name)\n",
    "path_masks = \"./Pruebas/{}/model.h5\".format(masks_model_name)\n",
    "\n",
    "# Generate a folder to save the plots that will be named comparacion + date and time\n",
    "import datetime\n",
    "import os\n",
    "now = datetime.datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "path = \"./Pruebas/Comparacion/comparacion_\" + date_time\n",
    "os.mkdir(path)\n",
    "\n",
    "# Write on the result.txt file the model names\n",
    "f = open(path + \"/results.txt\", \"w\")\n",
    "f.write(\"Modelo de landmarks: {}\\n\".format(landmarks_model_name))\n",
    "f.write(\"Modelo de máscaras: {}\\n\".format(masks_model_name))\n",
    "f.write(\"Fecha y hora: {}\\n\".format(date_time))\n",
    "f.write(\"-----------------------------------------------------------------\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 11s 64ms/step\n",
      "160/160 [==============================] - 10s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "model_landmarks = tf.keras.models.load_model(path_landmarks,custom_objects={'accuracy_landmarks': accuracy_landmarks})\n",
    "model_masks = tf.keras.models.load_model(path_masks, custom_objects={'dice_loss': dice_loss, 'dice_coefficient': dice_coefficient})\n",
    "\n",
    "predictions_landmarks = model_landmarks.predict(test_dataset_Landmarks)\n",
    "predictions_masks = model_masks.predict(test_dataset_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "#TODO: Investigate what the ssim function does\n",
    "def calculate_ssim(image1, image2):\n",
    "    # Calculate the Structural Similarity Index (SSI)\n",
    "    similarity_index, _ = ssim(image1, image2, full=True, data_range=image1.max() - image1.min())\n",
    "\n",
    "    # The SSI ranges from -1 to 1, where 1 indicates a perfect match\n",
    "    # We normalize it to the range [0, 1] to represent percentage similarity\n",
    "    percentage_similarity = (similarity_index + 1) / 2 * 100\n",
    "\n",
    "    return percentage_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot 5 images with their respective landmarks and masks.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize the images and masks\n",
    "\n",
    "def visualize_predictions(images, landmarks, masks, landmarks_predictions, masks_predictions):\n",
    "    num_images = len(images)\n",
    "    string = \"\"\n",
    "    for i in range(num_images):  # Renamed the inner loop variable to 'j'\n",
    "        image = images[i]\n",
    "        landmark = landmarks[i]\n",
    "        mask = masks[i]\n",
    "        landmark_prediction = landmarks_predictions[i]\n",
    "        mask_prediction = masks_predictions[i]\n",
    "\n",
    "        # Combine all channels of prediction_landmarks by taking the mean\n",
    "        combined_prediction = np.mean(landmark_prediction, axis=-1)\n",
    "\n",
    "        # CObine all channels of ground_truth_landmarks by taking the mean\n",
    "        combined_ground_truth = np.mean(landmark, axis=-1)\n",
    "\n",
    "        # Calculate the Structural Similarity Index (SSI) between the predicted and ground truth landmarks\n",
    "        percentage_similarity_lm = calculate_ssim(combined_prediction, combined_ground_truth)\n",
    "\n",
    "        # Calculate the mean absolute error between the predicted and ground truth landmarks\n",
    "        mean_abs_error_lm = np.mean(np.abs(combined_prediction - combined_ground_truth))\n",
    "        \n",
    "        # Calculate the Structural Similarity Index (SSI) between the predicted and ground truth masks\n",
    "        percentage_similarity_m = calculate_ssim(mask_prediction.reshape(112,112), mask.reshape(112,112))\n",
    "\n",
    "        # Calculate the mean absolute error between the predicted and ground truth masks\n",
    "        mean_abs_error_m = np.mean(np.abs(mask_prediction - mask))\n",
    "\n",
    "        # Append to a string the percentage similarity and the mean absolute error for the landmarks and the masks and its image number\n",
    "        string = string + \"Image \" + str(i) + \":\\n\" + \"Landmarks: \" + str(percentage_similarity_lm) + \"% similarity, \" + str(mean_abs_error_lm) + \" mean absolute error\\n\" + \"Masks: \" + str(percentage_similarity_m) + \"% similarity, \" + str(mean_abs_error_m) + \" mean absolute error\\n\"\n",
    "        string = string + \"\\n\"\n",
    "\n",
    "        # Generate a plot with two rows and three columns, for image, ground truth landmarks, and predicted landmarks\n",
    "        f, axarr = plt.subplots(2, 3, figsize=(20, 15))\n",
    "\n",
    "        # Plot the image\n",
    "        axarr[0, 0].imshow(image, cmap='gray')\n",
    "        axarr[0, 0].set_title('Image')\n",
    "\n",
    "        # Plot the ground truth landmarks\n",
    "        axarr[0, 1].imshow(image, cmap='gray')\n",
    "        axarr[0, 1].imshow(combined_ground_truth, alpha=0.5, cmap='jet')\n",
    "        axarr[0, 1].set_title('Ground Truth Landmarks')\n",
    "\n",
    "        # Plot the predicted landmarks\n",
    "        axarr[0, 2].imshow(image, cmap='gray')\n",
    "        axarr[0, 2].imshow(combined_prediction, alpha=0.5, cmap='jet')\n",
    "        axarr[0, 2].set_title('Predicted Landmarks')\n",
    "\n",
    "        # Plot the ground truth mask\n",
    "        axarr[1, 0].imshow(image, cmap='gray')\n",
    "        axarr[1, 0].imshow(mask, alpha=0.5, cmap='jet')\n",
    "        axarr[1, 0].set_title('Ground Truth Mask')\n",
    "\n",
    "        # Plot the predicted mask\n",
    "        axarr[1, 1].imshow(image, cmap='gray')\n",
    "        axarr[1, 1].imshow(mask_prediction, alpha=0.5, cmap='jet')\n",
    "        axarr[1, 1].set_title('Predicted Mask')\n",
    "\n",
    "        # Plot the predicted landmarks overlaid on the predicted mask\n",
    "        axarr[1, 2].imshow(mask, alpha=0.5, cmap='grey')\n",
    "        axarr[1, 2].imshow(combined_prediction, alpha=0.5, cmap='grey')\n",
    "        axarr[1, 2].set_title('Predicted Landmarks & Ground Truth Mask')\n",
    "\n",
    "        # Save the plot\n",
    "        plt.savefig(path + \"/plot_\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "    \n",
    "    return string\n",
    "\n",
    "num_samples_to_visualize = 5\n",
    "sample_indices = np.random.choice(len(test_images[:10]), num_samples_to_visualize, replace=False)\n",
    "\n",
    "sample_images = [test_images[i] for i in sample_indices]\n",
    "sample_landmarks = [test_Landmarks[i] for i in sample_indices]\n",
    "sample_masks = [test_masks[i] for i in sample_indices]\n",
    "landmark_predictions = [predictions_landmarks[i] for i in sample_indices]\n",
    "mask_predictions = [predictions_masks[i] for i in sample_indices]\n",
    "\n",
    "# Visualize the predictions\n",
    "string = visualize_predictions(sample_images, sample_landmarks, sample_masks, landmark_predictions, mask_predictions)\n",
    "\n",
    "# Save string to a file\n",
    "f = open(path + \"/results.txt\", \"a\")\n",
    "f.write(string)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the mean Structural Similarity Index (SSI) for the masks in the test set\n",
    "mean_ssim_mask = 0\n",
    "for i in range(len(test_masks)):\n",
    "    mask1 = test_masks[i].reshape(112,112)\n",
    "    mask2 = predictions_masks[i].reshape(112,112)\n",
    "    mean_ssim_mask += calculate_ssim(mask1, mask2)\n",
    "\n",
    "mean_ssim_mask /= len(test_masks)\n",
    "\n",
    "# Calculate the mean Structural Similarity Index (SSI) for the landmarks in the test set\n",
    "mean_ssim_landmark = 0\n",
    "for i in range(len(test_Landmarks)):\n",
    "    landmark1 = np.mean(test_Landmarks[i], axis=-1)\n",
    "    landmark2 = np.mean(predictions_landmarks[i], axis=-1)\n",
    "    mean_ssim_landmark += calculate_ssim(landmark1, landmark2)\n",
    "\n",
    "mean_ssim_landmark /= len(test_Landmarks)\n",
    "\n",
    "# Calculate the mean absolute error for the landmarks in the test set\n",
    "mean_abs_error_landmark = 0\n",
    "for i in range(len(test_Landmarks)):\n",
    "    landmark1 = np.mean(test_Landmarks[i], axis=-1)\n",
    "    landmark2 = np.mean(predictions_landmarks[i], axis=-1)\n",
    "    mean_abs_error_landmark += np.mean(np.abs(landmark1 - landmark2))\n",
    "\n",
    "mean_abs_error_landmark /= len(test_Landmarks)\n",
    "\n",
    "# Calculate the mean absolute error for the masks in the test set\n",
    "mean_abs_error_mask = 0\n",
    "for i in range(len(test_masks)):\n",
    "    mask1 = test_masks[i].reshape(112,112)\n",
    "    mask2 = predictions_masks[i].reshape(112,112)\n",
    "    mean_abs_error_mask += np.mean(np.abs(mask1 - mask2))\n",
    "\n",
    "mean_abs_error_mask /= len(test_masks)\n",
    "\n",
    "# Save the mean SSI and mean absolute error to a file\n",
    "f = open(path + \"/results.txt\", \"a\")\n",
    "f.write(\"\\n\")\n",
    "f.write(\"Mean SSI for Masks: \" + str(mean_ssim_mask) + \"\\n\")\n",
    "f.write(\"Mean SSI for Landmarks: \" + str(mean_ssim_landmark) + \"\\n\")\n",
    "f.write(\"Mean absolute error for Masks: \" + str(mean_abs_error_mask) + \"\\n\")\n",
    "f.write(\"Mean absolute error for Landmarks: \" + str(mean_abs_error_landmark) + \"\\n\")\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
