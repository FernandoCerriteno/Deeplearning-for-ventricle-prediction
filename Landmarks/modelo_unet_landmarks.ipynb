{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Allow GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "# Initialize GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Rutas a las carpetas de entrenamiento, prueba y validación para imágenes y máscaras\n",
    "train_frames_dir = '../Frames/TRAIN'\n",
    "train_Landmarks_dir = './Landmarks/TRAIN'\n",
    "test_frames_dir = '../Frames/TEST'\n",
    "test_Landmarks_dir = './Landmarks/TEST'\n",
    "val_frames_dir = '../Frames/VAL'\n",
    "val_Landmarks_dir = './Landmarks/VAL'\n",
    "\n",
    "# Funciones para cargar y preprocesar imagen y máscara y convertirlo a solo un canal\n",
    "def load_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def load_landmarks(file_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(file_path):\n",
    "        image=cv2.imread(os.path.join(file_path, filename))\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images.append(grayscale_image)\n",
    "\n",
    "    stacked_image = np.stack(images, axis=-1)  # axis=-1 indica la dimensión de los canales\n",
    "\n",
    "    return stacked_image\n",
    "\n",
    "train_image_files = [os.path.join(train_frames_dir, filename) for filename in os.listdir(train_frames_dir)]\n",
    "train_Landmarks_files = [os.path.join(train_Landmarks_dir, filename) for filename in os.listdir(train_Landmarks_dir)]\n",
    "test_image_files = [os.path.join(test_frames_dir, filename) for filename in os.listdir(test_frames_dir)]\n",
    "test_Landmarks_files = [os.path.join(test_Landmarks_dir, filename) for filename in os.listdir(test_Landmarks_dir)]\n",
    "val_image_files = [os.path.join(val_frames_dir, filename) for filename in os.listdir(val_frames_dir)]\n",
    "val_Landmarks_files = [os.path.join(val_Landmarks_dir, filename) for filename in os.listdir(val_Landmarks_dir)]\n",
    "\n",
    "train_images = [load_image(file) for file in train_image_files]\n",
    "train_Landmarks = [load_landmarks(file) for file in train_Landmarks_files]\n",
    "\n",
    "test_images = [load_image(file) for file in test_image_files]\n",
    "test_Landmarks = [load_landmarks(file) for file in test_Landmarks_files]\n",
    "\n",
    "val_images = [load_image(file) for file in val_image_files]\n",
    "val_Landmarks = [load_landmarks(file) for file in val_Landmarks_files]\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_Landmarks = np.array(train_Landmarks)\n",
    "test_images = np.array(test_images)\n",
    "test_Landmarks = np.array(test_Landmarks)\n",
    "val_images = np.array(val_images)\n",
    "val_Landmarks = np.array(val_Landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mr:\\Codes\\Reto\\Landmarks\\modelo_unet_landmarks.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, BatchNormalization, Activation, ReLU, Conv2DTranspose\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Llamamos a la funcion del modelo U-Net desde un archivo externo dentro de la ruta R:\\Codes\\Reto\\Modelos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mModelos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel3\u001b[39;00m \u001b[39mimport\u001b[39;00m unet_model\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Crear el modelo U-Net\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m unet_model(input_shape\u001b[39m=\u001b[39m(\u001b[39m112\u001b[39m, \u001b[39m112\u001b[39m, \u001b[39m1\u001b[39m), num_classes\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, output_activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, BatchNormalization, Activation, ReLU, Conv2DTranspose\n",
    "\n",
    "# Llamamos a la funcion del modelo U-Net desde un archivo externo dentro de la ruta R:\\Codes\\Reto\\Modelos\n",
    "from Modelos.model3 import unet_model\n",
    "\n",
    "# Crear el modelo U-Net\n",
    "model = unet_model(input_shape=(112, 112, 1), num_classes=7, output_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# with tf.device('CPU'):\n",
    "#     train_dataset = tf.data.Dataset.from_tensor_slices((train_images[:700], train_Landmarks[:700]))\n",
    "#     train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "#     val_dataset = tf.data.Dataset.from_tensor_slices((val_images[:300], val_Landmarks[:300]))\n",
    "#     val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "#     test_dataset = tf.data.Dataset.from_tensor_slices((test_images[:300], test_Landmarks[:300]))\n",
    "#     test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "with tf.device('CPU'):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_Landmarks))\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_Landmarks))\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images[:2550], test_Landmarks[:2550]))\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_flat = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_flat = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_flat * y_pred_flat)\n",
    "    return (2.0 * intersection + smooth) / (tf.keras.backend.sum(y_true_flat) + tf.keras.backend.sum(y_pred_flat) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(), loss=dice_loss, metrics=[dice_coefficient, 'accuracy'])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "933/933 [==============================] - 149s 146ms/step - loss: 5.0999 - accuracy: 0.1392 - val_loss: 5.0444 - val_accuracy: 0.0279\n",
      "Epoch 2/10\n",
      "933/933 [==============================] - 130s 140ms/step - loss: 5.0300 - accuracy: 0.1858 - val_loss: 5.0204 - val_accuracy: 0.0126\n",
      "Epoch 3/10\n",
      "933/933 [==============================] - 133s 143ms/step - loss: 5.1112 - accuracy: 0.1509 - val_loss: 5.1833 - val_accuracy: 7.9719e-05\n",
      "Epoch 4/10\n",
      "933/933 [==============================] - 129s 139ms/step - loss: 5.1834 - accuracy: 0.0151 - val_loss: 5.1833 - val_accuracy: 7.9719e-05\n",
      "Epoch 5/10\n",
      "933/933 [==============================] - 132s 142ms/step - loss: 5.1833 - accuracy: 0.0730 - val_loss: 5.1833 - val_accuracy: 7.9719e-05\n",
      "Epoch 6/10\n",
      "933/933 [==============================] - 133s 142ms/step - loss: 5.1833 - accuracy: 0.1555 - val_loss: 5.1833 - val_accuracy: 7.9719e-05\n",
      "Epoch 7/10\n",
      "933/933 [==============================] - 132s 142ms/step - loss: 5.1833 - accuracy: 0.1373 - val_loss: 5.1833 - val_accuracy: 7.9719e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253d2712160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos un callback para guardar el modelo cada 5 épocas y otro para detener el entrenamiento si no hay mejora en 10 épocas\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss')\n",
    "]\n",
    "\n",
    "# Entrenamos el modelo\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 751ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mr:\\Codes\\Reto\\Landmarks\\modelo_unet_landmarks.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Plot the ground truth\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(ground_truth[\u001b[39m0\u001b[39;49m], cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mjet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Codes/Reto/Landmarks/modelo_unet_landmarks.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Plot the prediction\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have a single input image or a batch of images\n",
    "input_image = test_images[0:1]\n",
    "\n",
    "# Perform prediction\n",
    "predictions = model.predict(input_image)\n",
    "\n",
    "# Get the predicted class for each pixel\n",
    "predicted_classes = np.argmax(predictions)\n",
    "\n",
    "# Get the ground truth class for each pixel\n",
    "ground_truth = np.argmax(test_Landmarks[0:1])\n",
    "\n",
    "# Plot the ground truth\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(ground_truth[0], cmap='jet')\n",
    "plt.show()\n",
    "\n",
    "# Plot the prediction\n",
    "plt.imshow(predicted_classes[0], cmap='jet')\n",
    "plt.show()\n",
    "\n",
    "# Plot the input image\n",
    "plt.imshow(input_image[0], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model history information to a json file\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a folder name\n",
    "name_folder = 'mascara_{}'.format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "path = '../../Modelos/Pruebas/{}/'.format(name_folder)\n",
    "os.mkdir(path)\n",
    "\n",
    "# Save history to a json file\n",
    "path_json = '{}history.json'.format(path)\n",
    "\n",
    "with open(path_json, 'w') as fp:\n",
    "    json.dump(history.history, fp)\n",
    "\n",
    "# Save model\n",
    "path_model = '{}model.h5'.format(path)\n",
    "model.save(path_model)\n",
    "\n",
    "# Save model summary to a txt file\n",
    "path_summary = '{}summary.txt'.format(path)\n",
    "with open(path_summary, 'w') as fp:\n",
    "    model.summary(print_fn=lambda x: fp.write(x + '\\n'))\n",
    "\n",
    "# Save model metrics to a txt file\n",
    "path_metrics = '{}metrics.txt'.format(path)\n",
    "with open(path_metrics, 'w') as fp:\n",
    "    fp.write('Test loss: {}\\n'.format(evaluation[0]))\n",
    "    fp.write('Test dice coefficient: {}\\n'.format(evaluation[1]))\n",
    "    fp.write('Test accuracy: {}\\n'.format(evaluation[2]))\n",
    "\n",
    "# Generate a folder inside the folder of the model for the images\n",
    "path_images = '{}images/'.format(path)\n",
    "os.mkdir(path_images)\n",
    "\n",
    "# Generate a folder inside the folder of the images for plot images\n",
    "path_plot_images = '{}plot_images/'.format(path_images)\n",
    "os.mkdir(path_plot_images)\n",
    "\n",
    "# Generate a folder inside the folder of the images for prediction images\n",
    "path_test_images = '{}predicitons/'.format(path_images)\n",
    "os.mkdir(path_test_images)\n",
    "\n",
    "# Save prediction images\n",
    "# Función para visualizar una muestra de imágenes y sus máscaras de segmentación predichas\n",
    "def visualize_segmentation(images, masks, predictions):\n",
    "    num_samples = len(images)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Imagen original\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title('Imagen Original')\n",
    "\n",
    "        # Máscara de segmentación real\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(masks[i], cmap='gray')\n",
    "        plt.title('Máscara Real')\n",
    "\n",
    "        # Máscara de segmentación predicha\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(predictions[i], cmap='gray')\n",
    "        plt.title('Máscara Predicha')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('{}{}.png'.format(path_test_images, i))\n",
    "\n",
    "# Supongamos que tienes un conjunto de datos de prueba con imágenes y máscaras\n",
    "# Puedes utilizar el modelo para obtener las máscaras predichas en el conjunto de prueba\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Elije algunas muestras aleatorias para visualizar\n",
    "num_samples_to_visualize = 5\n",
    "sample_indices = np.random.choice(len(test_images[:10]), num_samples_to_visualize, replace=False)\n",
    "\n",
    "sample_images = [test_images[i] for i in sample_indices]\n",
    "sample_masks = [test_Landmarks[i] for i in sample_indices]\n",
    "sample_predictions = [predictions[i] for i in sample_indices]\n",
    "\n",
    "# Llama a la función para visualizar las imágenes y máscaras\n",
    "visualize_segmentation(sample_images, sample_masks, sample_predictions)\n",
    "\n",
    "# Save plot images\n",
    "for i in ['accuracy', 'loss']:\n",
    "    plt.figure()\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history['val_{}'.format(i)])\n",
    "    plt.title('Model {}'.format(i))\n",
    "    plt.ylabel(i)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig('{}{}.png'.format(path_plot_images, i))\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
