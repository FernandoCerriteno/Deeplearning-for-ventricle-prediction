{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Allow GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "# Initialize GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\AI2\\Reto\\Landmarks\\modelo_unet_landmarks.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m test_Landmarks \u001b[39m=\u001b[39m [load_landmarks(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m test_Landmarks_files]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m val_images \u001b[39m=\u001b[39m [load_image(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m val_image_files]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m val_Landmarks \u001b[39m=\u001b[39m [load_landmarks(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m val_Landmarks_files]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m train_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(train_images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m train_Landmarks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(train_Landmarks)\n",
      "\u001b[1;32me:\\AI2\\Reto\\Landmarks\\modelo_unet_landmarks.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m test_Landmarks \u001b[39m=\u001b[39m [load_landmarks(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m test_Landmarks_files]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m val_images \u001b[39m=\u001b[39m [load_image(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m val_image_files]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m val_Landmarks \u001b[39m=\u001b[39m [load_landmarks(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m val_Landmarks_files]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m train_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(train_images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m train_Landmarks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(train_Landmarks)\n",
      "\u001b[1;32me:\\AI2\\Reto\\Landmarks\\modelo_unet_landmarks.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(file_path):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     image\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39;49mimread(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(file_path, filename))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     grayscale_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     images\u001b[39m.\u001b[39mappend(grayscale_image)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Rutas a las carpetas de entrenamiento, prueba y validación para imágenes y máscaras\n",
    "train_frames_dir = '../Frames/TRAIN'\n",
    "train_Landmarks_dir = './Landmarks/TRAIN'\n",
    "test_frames_dir = '../Frames/TEST'\n",
    "test_Landmarks_dir = './Landmarks/TEST'\n",
    "val_frames_dir = '../Frames/VAL'\n",
    "val_Landmarks_dir = './Landmarks/VAL'\n",
    "\n",
    "# Funciones para cargar y preprocesar imagen y máscara y convertirlo a solo un canal\n",
    "def load_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def load_landmarks(file_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(file_path):\n",
    "        image=cv2.imread(os.path.join(file_path, filename))\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images.append(grayscale_image)\n",
    "\n",
    "    stacked_image = np.stack(images, axis=-1)  # axis=-1 indica la dimensión de los canales\n",
    "    stacked_image = stacked_image / 255.0\n",
    "    return stacked_image\n",
    "\n",
    "train_image_files = [os.path.join(train_frames_dir, filename) for filename in os.listdir(train_frames_dir)]\n",
    "train_Landmarks_files = [os.path.join(train_Landmarks_dir, filename) for filename in os.listdir(train_Landmarks_dir)]\n",
    "test_image_files = [os.path.join(test_frames_dir, filename) for filename in os.listdir(test_frames_dir)]\n",
    "test_Landmarks_files = [os.path.join(test_Landmarks_dir, filename) for filename in os.listdir(test_Landmarks_dir)]\n",
    "val_image_files = [os.path.join(val_frames_dir, filename) for filename in os.listdir(val_frames_dir)]\n",
    "val_Landmarks_files = [os.path.join(val_Landmarks_dir, filename) for filename in os.listdir(val_Landmarks_dir)]\n",
    "\n",
    "train_images = [load_image(file) for file in train_image_files]\n",
    "train_Landmarks = [load_landmarks(file) for file in train_Landmarks_files]\n",
    "\n",
    "test_images = [load_image(file) for file in test_image_files]\n",
    "test_Landmarks = [load_landmarks(file) for file in test_Landmarks_files]\n",
    "\n",
    "val_images = [load_image(file) for file in val_image_files]\n",
    "val_Landmarks = [load_landmarks(file) for file in val_Landmarks_files]\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_Landmarks = np.array(train_Landmarks)\n",
    "test_images = np.array(test_images)\n",
    "test_Landmarks = np.array(test_Landmarks)\n",
    "val_images = np.array(val_images)\n",
    "val_Landmarks = np.array(val_Landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar que todas las imágenes y máscaras tengan el mismo tamaño\n",
    "print(\"Train images shape: \", train_images.shape)\n",
    "print(\"Train Landmarks shape: \", train_Landmarks.shape)\n",
    "print(\"Test images shape: \", test_images.shape)\n",
    "print(\"Test Landmarks shape: \", test_Landmarks.shape)\n",
    "print(\"Validation images shape: \", val_images.shape)\n",
    "print(\"Validation Landmarks shape: \", val_Landmarks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agremos el path de la carpeta de modelos para poder importar el modelo\n",
    "import sys\n",
    "sys.path.append(r'R:\\Codes\\Reto\\Modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, BatchNormalization, Activation, ReLU, Conv2DTranspose\n",
    "\n",
    "# Definición de la arquitectura U-Net\n",
    "def unet_model(input_shape=(112, 112, 1), n_classes=1, kernel_out=1, activation='sigmoid'):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = Conv2D(64, 3, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = Conv2D(64, 3, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = Conv2D(128, 3, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = Conv2D(256, 3, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = Conv2D(512, 3, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = ReLU()(conv5)\n",
    "    conv5 = Conv2D(1024, 3, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = ReLU()(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = concatenate([up6, drop4])\n",
    "    conv6 = Conv2D(512, 3, padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = Conv2D(512, 3, padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = concatenate([up7, conv3])\n",
    "    conv7 = Conv2D(256, 3, padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = ReLU()(conv7)\n",
    "    conv7 = Conv2D(256, 3, padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = ReLU()(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = concatenate([up8, conv2])\n",
    "    conv8 = Conv2D(128, 3, padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = ReLU()(conv8)\n",
    "    conv8 = Conv2D(128, 3, padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = ReLU()(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = concatenate([up9, conv1])\n",
    "    conv9 = Conv2D(64, 3, padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    conv9 = Conv2D(64, 3, padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = ReLU()(conv9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, kernel_out, activation=activation)(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10, name='U-Net_2')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = unet_model(input_shape=(112, 112, 1), n_classes=7, kernel_out=1, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# with tf.device('CPU'):\n",
    "#     train_dataset = tf.data.Dataset.from_tensor_slices((train_images[:700], train_Landmarks[:700]))\n",
    "#     train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "#     val_dataset = tf.data.Dataset.from_tensor_slices((val_images[:300], val_Landmarks[:300]))\n",
    "#     val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "#     test_dataset = tf.data.Dataset.from_tensor_slices((test_images[:300], test_Landmarks[:300]))\n",
    "#     test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "with tf.device('CPU'):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_Landmarks))\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_Landmarks))\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_Landmarks))\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_landmarks(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean Squared Error loss function for 7 landmarks.\n",
    "    Assumes y_true and y_pred are of shape (batch_size, 112, 112, 7).\n",
    "    \"\"\"\n",
    "    mse = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "    return mse\n",
    "\n",
    "def accuracy_landmarks(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy metric for 7 landmarks.\n",
    "    Assumes y_true and y_pred are of shape (batch_size, 112, 112, 7).\n",
    "    \"\"\"\n",
    "    # Extract the landmark values from y_true and y_pred\n",
    "    y_true_landmarks = y_true[..., :7]\n",
    "    y_pred_landmarks = y_pred[..., :7]\n",
    "\n",
    "    # Calculate the element-wise absolute difference\n",
    "    abs_diff = K.abs(y_true_landmarks - y_pred_landmarks)\n",
    "\n",
    "    # Create a mask where each element is 1 if the absolute difference is less than a threshold, otherwise 0\n",
    "    mask = K.cast(K.less(abs_diff, 0.5), dtype=tf.float32)\n",
    "\n",
    "    # Calculate the accuracy for each landmark\n",
    "    landmark_accuracy = K.mean(mask, axis=-1)\n",
    "\n",
    "    # Overall accuracy is the mean accuracy across all landmarks\n",
    "    overall_accuracy = K.mean(landmark_accuracy)\n",
    "\n",
    "    return overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\AI2\\Reto\\Landmarks\\modelo_unet_landmarks.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/AI2/Reto/Landmarks/modelo_unet_landmarks.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss_method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:126\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlookup_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m index_table_from_dataset\n\u001b[0;32m    125\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlookup_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m table_from_dataset\n\u001b[1;32m--> 126\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparsing_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_example_dataset\n\u001b[0;32m    127\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprefetching_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m copy_to_device\n\u001b[0;32m    128\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprefetching_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m prefetch_to_device\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\parsing_ops.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_spec\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_experimental_dataset_ops\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m parsing_ops\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragged\u001b[39;00m \u001b[39mimport\u001b[39;00m ragged_tensor\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_export\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_parsing_ops\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m math_ops\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m parsing_config\n\u001b[0;32m     24\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m# pylint: disable=wildcard-import,undefined-variable\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgen_parsing_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_config.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m math_ops\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_ops\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragged\u001b[39;00m \u001b[39mimport\u001b[39;00m ragged_math_ops\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragged\u001b[39;00m \u001b[39mimport\u001b[39;00m ragged_tensor\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_logging\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_math_ops.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m check_ops\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_ragged_math_ops\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_fn\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m math_ops\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m nn_ops\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py:21\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m\"\"\"Functional operations.\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m ag_ctx \u001b[39mas\u001b[39;00m autograph_ctx\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpl\u001b[39;00m \u001b[39mimport\u001b[39;00m api \u001b[39mas\u001b[39;00m autograph\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\__init__.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m ConversionOptions\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m Feature\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoGraphError\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m convert\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m converted_call\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m conditional_expressions\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m continue_statements\n\u001b[1;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m directives\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m functions\n",
      "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\control_flow.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyct\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatic_analysis\u001b[39;00m \u001b[39mimport\u001b[39;00m activity\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyct\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatic_analysis\u001b[39;00m \u001b[39mimport\u001b[39;00m annos\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyct\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatic_analysis\u001b[39;00m \u001b[39mimport\u001b[39;00m liveness\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyct\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatic_analysis\u001b[39;00m \u001b[39mimport\u001b[39;00m reaching_definitions\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyct\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatic_analysis\u001b[39;00m \u001b[39mimport\u001b[39;00m reaching_fndefs\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1040\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loss_method = 'mean_squared_error'\n",
    "\n",
    "metrics_list = ['mean_squared_error', accuracy_landmarks]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=loss_method, metrics=metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos un callback para guardar el modelo cada 5 épocas y otro para detener el entrenamiento si no hay mejora en 10 épocas\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, mode='min', monitor='val_loss'),\n",
    "]\n",
    "\n",
    "# Entrenamos el modelo\n",
    "history = model.fit(train_dataset, epochs=100, validation_data=val_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model history information to a json file\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a folder name\n",
    "name_folder = 'landmark_{}'.format(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "path = '../Pruebas/{}/'.format(name_folder)\n",
    "os.mkdir(path)\n",
    "\n",
    "# Save history to a json file\n",
    "path_json = '{}history.json'.format(path)\n",
    "\n",
    "with open(path_json, 'w') as fp:\n",
    "    json.dump(history.history, fp)\n",
    "\n",
    "# Save model\n",
    "path_model = '{}model.h5'.format(path)\n",
    "model.save(path_model)\n",
    "\n",
    "# Save model summary to a txt file\n",
    "path_summary = '{}summary.txt'.format(path)\n",
    "with open(path_summary, 'w') as fp:\n",
    "    model.summary(print_fn=lambda x: fp.write(x + '\\n'))\n",
    "\n",
    "# Save model metrics to a txt file\n",
    "path_metrics = '{}metrics.txt'.format(path)\n",
    "with open(path_metrics, 'w') as fp:\n",
    "    fp.write('Test loss: {}\\n'.format(evaluation[0]))\n",
    "    fp.write('Test accuracy_landmarks: {}\\n'.format(evaluation[1]))\n",
    "    fp.write('Model optimizer: {}\\n'.format(model.optimizer.__class__.__name__))\n",
    "    fp.write('Model activation: {}\\n'.format(model.layers[-1].activation.__name__))\n",
    "    fp.write('Model learning rate: {}\\n'.format(model.optimizer.lr.numpy()))\n",
    "    fp.write('Model loss method: {}\\n'.format(loss_method))\n",
    "\n",
    "# Generate a folder inside the folder of the model for the images\n",
    "path_images = '{}images/'.format(path)\n",
    "os.mkdir(path_images)\n",
    "\n",
    "# Generate a folder inside the folder of the images for plot images\n",
    "path_plot_images = '{}plot_images/'.format(path_images)\n",
    "os.mkdir(path_plot_images)\n",
    "\n",
    "# Generate a folder inside the folder of the images for prediction images\n",
    "path_test_images = '{}predicitons/'.format(path_images)\n",
    "os.mkdir(path_test_images)\n",
    "\n",
    "# Save prediction images\n",
    "# Función para visualizar una muestra de imágenes y sus máscaras de segmentación predichas\n",
    "def visualize_landmarks(images, landmarks, predictions):\n",
    "    num_images = len(images)\n",
    "\n",
    "    for i in range(num_images):  # Renamed the inner loop variable to 'j'\n",
    "        # Set up the subplots\n",
    "        image = images[i].reshape((112, 112))\n",
    "        prediction = predictions[i].reshape((112, 112, 7)) * 255.0\n",
    "        landmark = landmarks[i] * 255.0  # No need to reshape\n",
    "        fig, axs = plt.subplots(2, 9, figsize=(15, 5))\n",
    "\n",
    "        # Display the test image spanning the first two columns of both rows\n",
    "        axs[0, 0].imshow(image, cmap='grey')\n",
    "        axs[0, 0].axis('off')\n",
    "        axs[0, 0].set_title('Test Image') \n",
    "        axs[1, 0].axis('off')\n",
    "\n",
    "        # Combine all channels of prediction_landmarks by taking the mean\n",
    "        combined_prediction = np.mean(prediction, axis=-1)\n",
    "\n",
    "        # CObine all channels of ground_truth_landmarks by taking the mean\n",
    "        combined_ground_truth = np.mean(landmark, axis=-1)\n",
    "\n",
    "        # Display the predicted and ground truth landmarks in the first column of the second row all in one image\n",
    "        axs[0, 1].imshow(combined_prediction, cmap='grey')\n",
    "        axs[0, 1].set_title('Predicted')\n",
    "        axs[0, 1].axis('off')\n",
    "        axs[1, 1].imshow(combined_ground_truth, cmap='grey')\n",
    "        axs[1, 1].set_title('Ground Truth')\n",
    "        axs[1, 1].axis('off')\n",
    "\n",
    "        # Display the predicted landmarks in the first row\n",
    "        for k in range(7):  # Renamed the loop variable to 'k'\n",
    "            axs[0, k+2].imshow(prediction[ :, :, k], cmap='grey')\n",
    "            axs[0, k+2].axis('off')\n",
    "            axs[0, k+2].set_title('Predicted ' + str(k + 1))\n",
    "\n",
    "        # Display the ground truth landmarks in the second row\n",
    "        for k in range(7):  # Renamed the loop variable to 'k'\n",
    "            axs[1, k+2].imshow(landmark[ :, :, k], cmap='grey')\n",
    "            axs[1, k+2].axis('off')\n",
    "            axs[1, k+2].set_title('Ground Truth ' + str(k + 1))\n",
    "\n",
    "        plt.savefig('{}{}.png'.format(path_test_images, i))\n",
    "\n",
    "\n",
    "# Supongamos que tienes un conjunto de datos de prueba con imágenes y máscaras\n",
    "# Puedes utilizar el modelo para obtener las máscaras predichas en el conjunto de prueba\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Elije algunas muestras aleatorias para visualizar\n",
    "num_samples_to_visualize = 5\n",
    "sample_indices = np.random.choice(len(test_images[:10]), num_samples_to_visualize, replace=False)\n",
    "\n",
    "sample_images = [test_images[i] for i in sample_indices]\n",
    "sample_landmarks = [test_Landmarks[i] for i in sample_indices]\n",
    "sample_predictions = [predictions[i] for i in sample_indices]\n",
    "\n",
    "# Llama a la función para visualizar las imágenes y máscaras\n",
    "visualize_landmarks(sample_images, sample_landmarks, sample_predictions)\n",
    "\n",
    "# Save plot images\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy_landmarks'])\n",
    "plt.plot(history.history['val_accuracy_landmarks'])\n",
    "plt.title('Model accuracy_landmarks')\n",
    "plt.ylabel('accuracy_landmarks')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('{}{}.png'.format(path_plot_images, 'accuracy_landmarks'))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('{}loss.png'.format(path_plot_images))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
